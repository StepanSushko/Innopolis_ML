{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ДЗ 17: Seq2Seq и Seq2Seq + Attention (английский → русский)\n",
        "\n",
        "Кратко:\n",
        "\n",
        "* **датасет перевода с английского на русский** на Hugging Face: `Helsinki-NLP/opus-100` (`en` / `ru`),\n",
        "* обучаем общий SentencePiece‑токенизатор,\n",
        "* строим две модели:\n",
        "  * Seq2Seq на GRU,\n",
        "  * Seq2Seq + Bahdanau Attention,\n",
        "* обучаем обе модели на тренировочной выборке,\n",
        "* переводим 30 предложений из тестовой выборки обеими моделями и сравниваем результаты.\n",
        "\n",
        "Особенности реализации:\n",
        "\n",
        "* учёт паддингов через `pack_padded_sequence` / `pad_packed_sequence` в энкодере,\n",
        "* 2 слоя GRU + `dropout`,\n",
        "* shared embeddings + weight tying,\n",
        "* label smoothing, gradient clipping,\n",
        "* план по teacher forcing (1.0 → 0.6),\n",
        "* градиентная аккумуляция и AMP (FP16) для работы для работы в уловиях умеренного объёма доступной памяти GPU 16(Гб).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "from contextlib import nullcontext\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "import sentencepiece as spm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31460934",
      "metadata": {},
      "source": [
        "## Корпус текстов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 1000000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n",
            "{'en': \"Yeah, that's not exactly...\", 'ru': 'Да, но не совсем...'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1000000, 2000, 2000)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "pair = \"en-ru\"\n",
        "LANG_SRC, LANG_TGT = pair.split(\"-\")\n",
        "ds = load_dataset(\"Helsinki-NLP/opus-100\", pair)\n",
        "print(ds)\n",
        "print(ds[\"train\"][0][\"translation\"])\n",
        "\n",
        "ds_train = ds[\"train\"]\n",
        "ds_valid   = ds[\"validation\"] if \"validation\" in ds else ds.get(\"dev\", None)\n",
        "ds_test  = ds[\"test\"] if \"test\" in ds else None\n",
        "if ds_test is None:\n",
        "    tmp = ds_train.train_test_split(test_size=0.05, seed=SEED)\n",
        "    ds_train, ds_test = tmp[\"train\"], tmp[\"test\"]\n",
        "if ds_valid is None:\n",
        "    tmp = ds_train.train_test_split(test_size=0.05, seed=SEED)\n",
        "    ds_train, ds_valid = tmp[\"train\"], tmp[\"test\"]\n",
        "    \n",
        "len(ds_train), len(ds_valid), len(ds_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "251aa46d",
      "metadata": {},
      "source": [
        "## Обучение токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f981d946",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SentencePiece модель загружена.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 16000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VOCAB_SIZE = 16000 # Размер словаря\n",
        "SPM_MODEL_PREFIX = \"spm_bpe_opus100_en_ru_16k_2\"\n",
        "SPM_MODEL_FILE = f\"{SPM_MODEL_PREFIX}.model\"\n",
        "\n",
        "if not Path(SPM_MODEL_FILE).exists():\n",
        "    corpus_path = Path(\"spm_corpus_opus100_en_ru_2.txt\")\n",
        "    MAX_LINES = 1_000_000  # максимум пар предложений для корпуса SPM\n",
        "\n",
        "    with corpus_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for i, ex in enumerate(tqdm(ds_train, desc=\"SPM corpus (OPUS-100)\")):\n",
        "            if i >= MAX_LINES:\n",
        "                break\n",
        "            tr = ex[\"translation\"]\n",
        "            src_text = tr[LANG_SRC].replace(\"\\n\", \" \")\n",
        "            tgt_text = tr[LANG_TGT].replace(\"\\n\", \" \")\n",
        "            f.write(src_text + \"\\n\")\n",
        "            f.write(tgt_text + \"\\n\")\n",
        "\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=str(corpus_path),\n",
        "        model_prefix=SPM_MODEL_PREFIX,\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        model_type=\"bpe\", # Byte Pair Encoding (BPE) — это метод постепенного слияния наиболее часто встречающихся пар байтов (или символов) в более длинные токены.  Слова, которых не было в обучающей выборке, можно разбить на известные подслова.\n",
        "        character_coverage=0.9995,\n",
        "        pad_id=0,\n",
        "        unk_id=1,\n",
        "        bos_id=2,\n",
        "        eos_id=3,\n",
        "        input_sentence_size=1_000_000, # был взят весь миллион предложений\n",
        "        shuffle_input_sentence=True,\n",
        "    )\n",
        "    print(\"SentencePiece модель обучена.\")\n",
        "else:\n",
        "    print(\"SentencePiece модель загружена.\")\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(SPM_MODEL_FILE)\n",
        "\n",
        "PAD_ID = sp.pad_id()\n",
        "UNK_ID = sp.unk_id()\n",
        "BOS_ID = sp.bos_id()\n",
        "EOS_ID = sp.eos_id()\n",
        "VOCAB_SIZE = sp.vocab_size()\n",
        "\n",
        "PAD_ID, UNK_ID, BOS_ID, EOS_ID, VOCAB_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeff993a",
      "metadata": {},
      "source": [
        "## Токенизация и создание батчей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([192, 80])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "MAX_LEN = 80  # максимум токенов SPM (включая BOS/EOS)\n",
        "\n",
        "def encode_text(text: str, max_len: int = MAX_LEN,\n",
        "                add_bos: bool = True, add_eos: bool = True):\n",
        "    \"\"\"\n",
        "    Преобразует текст в последовательность идентификаторов токенов и возвращает её в виде тензора PyTorch.\n",
        "\n",
        "    Функция выполняет токенизацию входного текста с использованием внешнего токенизатора `SentencePiece`,\n",
        "    добавляет специальные токены начала (BOS) и конца (EOS) последовательности при необходимости,\n",
        "    обрезает результат до заданной максимальной длины и преобразует в тензор.\n",
        "    \"\"\"\n",
        "    \n",
        "    ids = sp.encode(text, out_type=int)\n",
        "    if add_bos:\n",
        "        ids = [BOS_ID] + ids\n",
        "    if add_eos:\n",
        "        ids = ids + [EOS_ID]\n",
        "    if len(ids) > max_len:\n",
        "        ids = ids[:max_len]\n",
        "    return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, hf_split, lang_src: str, lang_tgt: str, max_len: int = MAX_LEN):\n",
        "        self.data = hf_split\n",
        "        self.lang_src = lang_src\n",
        "        self.lang_tgt = lang_tgt\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Извлекает и кодирует пару текстов по заданному индексу.\n",
        "        \"\"\"\n",
        "        tr = self.data[idx][\"translation\"]\n",
        "        src_text = tr[self.lang_src]\n",
        "        tgt_text = tr[self.lang_tgt]\n",
        "        src = encode_text(src_text, max_len=self.max_len)\n",
        "        tgt = encode_text(tgt_text, max_len=self.max_len)\n",
        "        return src, tgt\n",
        "\n",
        "\n",
        "def pad_sequence_sp(seqs):\n",
        "    \"\"\"\n",
        "    Дополняет последовательности до одинаковой длины, создавая батч для обработки в PyTorch.\n",
        "\n",
        "    Функция принимает список тензоров разной длины, определяет максимальную длину,\n",
        "    и дополняет более короткие последовательности значением PAD_ID до этой длины,\n",
        "    формируя двумерный тензор с равномерными размерами.\n",
        "    \"\"\"\n",
        "    lens = [len(s) for s in seqs]\n",
        "    max_len = max(lens)\n",
        "    out = torch.full((len(seqs), max_len), PAD_ID, dtype=torch.long)\n",
        "    for i, s in enumerate(seqs):\n",
        "        out[i, : len(s)] = s\n",
        "    return out\n",
        "\n",
        "\n",
        "def collate_fn_sp(batch):\n",
        "    \"\"\"\n",
        "    Функция для объединения списка образцов в батч с использованием дополнения (padding).\n",
        "\n",
        "    Используется как collate_fn в DataLoader PyTorch. Принимает список пар тензоров\n",
        "    (источник, цель), разделяет их на отдельные списки, выравнивает последовательности\n",
        "    по максимальной длине с помощью pad_sequence_sp и возвращает батчи с соответствующими длинами.\n",
        "    \"\"\"\n",
        "    src_list, tgt_list = zip(*batch)\n",
        "    src_pad = pad_sequence_sp(src_list)   # форма [B,S]  B — размер батча, S — максимальная длина в батче для источника, T — для цели\n",
        "    tgt_pad = pad_sequence_sp(tgt_list)   # форма [B,T]\n",
        "    src_len = (src_pad != PAD_ID).sum(dim=1)  # [B]\n",
        "    return src_pad, tgt_pad, src_len\n",
        "\n",
        "\n",
        "train_dataset = TranslationDataset(ds_train, LANG_SRC, LANG_TGT)\n",
        "valid_dataset = TranslationDataset(ds_valid, LANG_SRC, LANG_TGT)\n",
        "test_dataset  = TranslationDataset(ds_test,  LANG_SRC, LANG_TGT)\n",
        "\n",
        "BATCH_SIZE = 192\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          collate_fn=collate_fn_sp, num_workers=0, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          collate_fn=collate_fn_sp, num_workers=0, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          collate_fn=collate_fn_sp, num_workers=0, pin_memory=True)\n",
        "\n",
        "next(iter(train_loader))[0].shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8cce74",
      "metadata": {},
      "source": [
        "## Определение нейросетевых моделей seq2seq (энкодер-декор и энкодер-декор-внимание)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df84e52",
      "metadata": {},
      "source": [
        "### Определение классов энкодера, декодера, энкодер+внимание, декодер+внимание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Модуль энкодера на основе GRU.\n",
        "\n",
        "    Энкодер преобразует входную последовательность токенов в скрытые состояния с использованием\n",
        "    эмбеддингов и многослойной GRU-сети. Поддерживает обработку паддированных последовательностей\n",
        "    с помощью pack_padded_sequence для эффективного обучения.\n",
        "\n",
        "    embedding : nn.Embedding\n",
        "        Слой эмбеддингов, преобразующий индексы токенов в векторные представления.\n",
        "        Использует PAD_ID как индекс для игнорирования паддинг-токенов.\n",
        "    dropout : nn.Dropout\n",
        "        Слой дропаута для регуляризации, применяется к эмбеддингам.\n",
        "    gru : nn.GRU\n",
        "        Многослойная рекуррентная сеть GRU.\n",
        "        При наличии более чем одного слоя применяется дропаут между слоями.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(\n",
        "            emb_dim,\n",
        "            hid_dim,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "    def forward(self, src, lengths=None):\n",
        "        # src: [B,S]\n",
        "        emb = self.dropout(self.embedding(src))  # [B,S,E]\n",
        "        if lengths is not None:\n",
        "            packed = nn.utils.rnn.pack_padded_sequence(\n",
        "                emb,\n",
        "                lengths.cpu(),\n",
        "                batch_first=True,\n",
        "                enforce_sorted=False,\n",
        "            )\n",
        "            packed_out, hidden = self.gru(packed)\n",
        "            outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
        "        else:\n",
        "            outputs, hidden = self.gru(emb)\n",
        "        # outputs: [B,S,H], hidden: [L,B,H]\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Модуль декодера на основе GRU для задач генерации последовательностей, таких как машинный перевод.\n",
        "\n",
        "    Декодер принимает на вход предыдущий токен и скрытое состояние из энкодера, обрабатывает его\n",
        "    с помощью слоя эмбеддингов и многослойной GRU-сети, а затем выдаёт логиты для предсказания следующего токена.\n",
        "\n",
        "    embedding : nn.Embedding\n",
        "        Слой эмбеддингов, преобразующий индексы токенов в векторные представления.\n",
        "        Использует PAD_ID как индекс для игнорирования паддинг-токенов.\n",
        "    fc_out : nn.Linear\n",
        "        Линейный слой, преобразующий выход GRU в логиты по всему словарю, используется для предсказания следующего токена.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(\n",
        "            emb_dim,\n",
        "            hid_dim,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(hid_dim, vocab_size, bias=True)\n",
        "\n",
        "    def forward(self, input_tok, hidden):\n",
        "        # input_tok: [B]\n",
        "        emb = self.dropout(self.embedding(input_tok.unsqueeze(1)))  # [B,1,E]\n",
        "        out, hidden = self.gru(emb, hidden)\n",
        "        logits = self.fc_out(out.squeeze(1))  # [B,V]\n",
        "        return logits, hidden\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Модуль механизма внимания Бахданау для рекуррентных моделей.\n",
        "\n",
        "    Реализует аддитивное внимание, которое позволяет декодеру\n",
        "    сосредотачиваться на различных частях входной последовательности при генерации каждого токена.\n",
        "    \"\"\"\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(hid_dim, hid_dim)\n",
        "        self.W2 = nn.Linear(hid_dim, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, hidden, enc_outs, mask=None):\n",
        "        # hidden: [L,B,H] → берём последний слой\n",
        "        h = hidden[-1]  # [B,H]\n",
        "        # enc_outs: [B,S,H]\n",
        "        score = self.v(torch.tanh(self.W1(enc_outs) + self.W2(h).unsqueeze(1)))  # [B,S,1]\n",
        "        attn = torch.softmax(score, dim=1)  # [B,S,1]\n",
        "        if mask is not None:\n",
        "            attn = attn * mask.unsqueeze(-1)\n",
        "            attn = attn / (attn.sum(dim=1, keepdim=True) + 1e-9)\n",
        "        ctx = (attn * enc_outs).sum(dim=1)  # [B,H]\n",
        "        return ctx, attn.squeeze(-1)        # [B,H], [B,S]\n",
        "\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Декодер с механизмом внимания Бахданау.\n",
        "\n",
        "    Этот модуль расширяет стандартный GRU-декодер, добавляя механизм внимания,\n",
        "    который позволяет модели динамически фокусироваться на различных частях\n",
        "    входной последовательности при генерации каждого токена. Объединяет эмбеддинг\n",
        "    входного токена и контекстный вектор (на основе внимания) перед подачей в GRU.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_ID)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(\n",
        "            emb_dim + hid_dim,\n",
        "            hid_dim,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(hid_dim, vocab_size, bias=True)\n",
        "        self.attn = BahdanauAttention(hid_dim)\n",
        "\n",
        "    def forward(self, input_tok, hidden, enc_outs, src_mask=None):\n",
        "        emb = self.dropout(self.embedding(input_tok.unsqueeze(1)))  # [B,1,E]\n",
        "        ctx, _ = self.attn(hidden, enc_outs, mask=src_mask)         # [B,H]\n",
        "        x = torch.cat([emb, ctx.unsqueeze(1)], dim=-1)              # [B,1,E+H]\n",
        "        out, hidden = self.gru(x, hidden)\n",
        "        logits = self.fc_out(out.squeeze(1))\n",
        "        return logits, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7be11f",
      "metadata": {},
      "source": [
        "### Определение моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def make_src_mask(src):\n",
        "    return (src != PAD_ID)  # [B,S], bool\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    \"\"\"\n",
        "    Модель Seq2Seq.\n",
        "\n",
        "    Архитектура объединяет энкодер и декодер.\n",
        "    Поддерживает режим обучения с параметром `tf_ratio` -- Вероятность использования teacher forcing (значение от 0 до 1). При значении 1 — всегда использует истинные токены, при 0 — только предсказания модели.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt, lengths=None, tf_ratio: float = 1.0):\n",
        "        enc_outs, hidden = self.encoder(src, lengths)\n",
        "        input_tok = tgt[:, 0]   # BOS\n",
        "        outs = []\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            logits, hidden = self.decoder(input_tok, hidden)\n",
        "            outs.append(logits.unsqueeze(1))\n",
        "            with torch.no_grad():\n",
        "                use_tf = torch.rand(input_tok.size(0), device=tgt.device) < tf_ratio\n",
        "                greedy = logits.argmax(dim=-1)\n",
        "                next_tok = torch.where(use_tf, tgt[:, t], greedy)\n",
        "            input_tok = next_tok\n",
        "        return torch.cat(outs, dim=1)  # [B,T-1,V]\n",
        "\n",
        "\n",
        "class Seq2SeqAttn(nn.Module):\n",
        "    \"\"\"\n",
        "    Модель последовательность-в-последовательность с механизмом внимания.\n",
        "\n",
        "    Архитектура объединяет энкодер и декодер с поддержкой внимания, что позволяет\n",
        "    декодеру динамически обращаться к различным частям входной последовательности\n",
        "    при генерации каждого токена выходной последовательности.\n",
        "    \n",
        "    Выполняет кодирование входной последовательности и последовательную генерацию выхода с использованием teacher forcing (tf_ratio) и механизма внимания.\n",
        "    На каждом шаге следующий входной токен выбирается: с вероятностью `tf_ratio` — из целевой последовательности (истина), иначе — жадное предсказание модели (inference).\n",
        "    Это позволяет комбинировать обучение с учителем и автономную генерацию.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, lengths=None, tf_ratio: float = 1.0):\n",
        "        enc_outs, hidden = self.encoder(src, lengths)\n",
        "        input_tok = tgt[:, 0]\n",
        "        outs = []\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            logits, hidden = self.decoder(input_tok, hidden, enc_outs, src_mask)\n",
        "            outs.append(logits.unsqueeze(1))\n",
        "            with torch.no_grad():\n",
        "                use_tf = torch.rand(input_tok.size(0), device=tgt.device) < tf_ratio\n",
        "                greedy = logits.argmax(dim=-1)\n",
        "                next_tok = torch.where(use_tf, tgt[:, t], greedy)\n",
        "            input_tok = next_tok\n",
        "        return torch.cat(outs, dim=1)\n",
        "\n",
        "\n",
        "def share_and_tie(enc: Encoder, dec: nn.Module):\n",
        "    dec.embedding.weight = enc.embedding.weight\n",
        "    if hasattr(dec, \"fc_out\"):\n",
        "        dec.fc_out.weight = dec.embedding.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2468a1",
      "metadata": {},
      "source": [
        "## Обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Staff\\Иннополис\\Innopolis\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "EPOCHS = 25\n",
        "EMB_DIM = 512\n",
        "HID_DIM = 512\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "ACCUM_STEPS = 2  # эффективный батч ≈ BATCH_SIZE * ACCUM_STEPS\n",
        "\n",
        "def build_seq2seq():\n",
        "    enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, num_layers=2, dropout=0.2)\n",
        "    dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM, num_layers=2, dropout=0.2)\n",
        "    share_and_tie(enc, dec)\n",
        "    return Seq2Seq(enc, dec)\n",
        "\n",
        "def build_seq2seq_attn():\n",
        "    enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, num_layers=2, dropout=0.2)\n",
        "    dec = AttnDecoder(VOCAB_SIZE, EMB_DIM, HID_DIM, num_layers=2, dropout=0.2)\n",
        "    share_and_tie(enc, dec)\n",
        "    return Seq2SeqAttn(enc, dec)\n",
        "\n",
        "\n",
        "model_s2s = build_seq2seq().to(DEVICE)\n",
        "model_attn = build_seq2seq_attn().to(DEVICE)\n",
        "\n",
        "opt_s2s = torch.optim.AdamW(model_s2s.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.98))\n",
        "opt_attn = torch.optim.AdamW(model_attn.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.98))\n",
        "\n",
        "sched_s2s = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    opt_s2s, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
        ")\n",
        "sched_attn = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    opt_attn, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=0.1)\n",
        "\n",
        "\n",
        "def tf_schedule(epoch: int):\n",
        "    # teacher forcing: 1.0 → 0.6\n",
        "    return max(0.6, 1.0 - 0.02 * (epoch - 1))\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, clip=1.0, tf_ratio=1.0, accum_steps=2):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
        "    autocast_ctx = torch.cuda.amp.autocast if DEVICE.type == \"cuda\" else nullcontext\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    for step, (src, tgt, src_len) in enumerate(tqdm(loader, desc=\"train\", leave=False), start=1):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "        src_len = src_len.to(DEVICE)\n",
        "\n",
        "        with autocast_ctx(dtype=torch.float16 if DEVICE.type == \"cuda\" else None):\n",
        "            if isinstance(model, Seq2SeqAttn):\n",
        "                logits = model(src, tgt,\n",
        "                               src_mask=make_src_mask(src),\n",
        "                               lengths=src_len,\n",
        "                               tf_ratio=tf_ratio)\n",
        "            else:\n",
        "                logits = model(src, tgt, lengths=src_len, tf_ratio=tf_ratio)\n",
        "            loss = criterion(\n",
        "                logits.reshape(-1, logits.size(-1)),\n",
        "                tgt[:, 1:].reshape(-1)\n",
        "            )\n",
        "            loss = loss / accum_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if step % accum_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        total += loss.item() * accum_steps\n",
        "\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    autocast_ctx = torch.cuda.amp.autocast if DEVICE.type == \"cuda\" else nullcontext\n",
        "\n",
        "    for src, tgt, src_len in tqdm(loader, desc=\"valid\", leave=False):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "        src_len = src_len.to(DEVICE)\n",
        "\n",
        "        with autocast_ctx(dtype=torch.float16 if DEVICE.type == \"cuda\" else None):\n",
        "            if isinstance(model, Seq2SeqAttn):\n",
        "                logits = model(src, tgt,\n",
        "                               src_mask=make_src_mask(src),\n",
        "                               lengths=src_len,\n",
        "                               tf_ratio=1.0)\n",
        "            else:\n",
        "                logits = model(src, tgt, lengths=src_len, tf_ratio=1.0)\n",
        "            loss = criterion(\n",
        "                logits.reshape(-1, logits.size(-1)),\n",
        "                tgt[:, 1:].reshape(-1)\n",
        "            )\n",
        "        total += loss.item()\n",
        "\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "\n",
        "def train_and_save(model, optimizer, scheduler, model_path, label, history_list):\n",
        "    best = float(\"inf\")\n",
        "    bad = 0\n",
        "    patience = 6\n",
        "    start_epoch = len(history_list)\n",
        "    print(f\"{label}: обучение начинается с эпохи {start_epoch + 1}\")\n",
        "\n",
        "    for k in range(1, EPOCHS + 1):\n",
        "        epoch = start_epoch + k\n",
        "        tf_ratio = tf_schedule(epoch)\n",
        "\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, optimizer, criterion,\n",
        "            clip=1.0, tf_ratio=tf_ratio, accum_steps=ACCUM_STEPS\n",
        "        )\n",
        "        val_loss = eval_epoch(model, valid_loader, criterion)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history_list.append((train_loss, val_loss))\n",
        "        print(f\"[{label}] Эпоха {epoch:02d} | tf={tf_ratio:.2f} | \"\n",
        "              f\"train={train_loss:.3f} | val={val_loss:.3f}\")\n",
        "\n",
        "        if val_loss + 1e-4 < best:\n",
        "            best = val_loss\n",
        "            bad = 0\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(f\"{label}: ранняя остановка на эпохе {epoch:02d}\")\n",
        "                break\n",
        "\n",
        "    print(f\"{label}: лучшие веса сохранены → {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "history_s2s = []\n",
        "history_attn = []\n",
        "\n",
        "MODEL_S2S_PATH = \"model_seq2seq_en_ru.pt\"\n",
        "MODEL_ATT_PATH = \"model_seq2seq_attn_en_ru.pt\"\n",
        "\n",
        "# Запуск обучения:\n",
        "#train_and_save(model_s2s, opt_s2s, sched_s2s, MODEL_S2S_PATH, \"Seq2Seq\", history_s2s)\n",
        "#train_and_save(model_attn, opt_attn, sched_attn, MODEL_ATT_PATH, \"Seq2Seq+Attn\", history_attn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fff1e5c",
      "metadata": {},
      "source": [
        "## Инференс моделей на 30 примерах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\stepa\\AppData\\Local\\Temp\\ipykernel_31864\\3802357344.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_s2s.load_state_dict(torch.load(MODEL_S2S_PATH, map_location=DEVICE))\n",
            "C:\\Users\\stepa\\AppData\\Local\\Temp\\ipykernel_31864\\3802357344.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_attn.load_state_dict(torch.load(MODEL_ATT_PATH, map_location=DEVICE))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Пример 1 ===\n",
            "SRC: If you only stay there.\n",
            "REF: Только бы не вылететь.\n",
            "S2S: Если ты останешься здесь.\n",
            "ATT: Если ты оста остаешься там.\n",
            "\n",
            "=== Пример 2 ===\n",
            "SRC: I don't know how you do it, Pop, carrying these boxes around every day.\n",
            "REF: И как ты только справляешься, папа, таская эти коробки взад-вперед целый день.\n",
            "S2S: Я не знаю, как ты делаешь, но каждый день каждый день.\n",
            "ATT: Я не знаю, как ты это делаешь, По,, эти этики в каждый день.\n",
            "\n",
            "=== Пример 3 ===\n",
            "SRC: We might have a slight edge in mediation.\n",
            "REF: Возможно, у нас есть небольшое преимущество в переговорах.\n",
            "S2S: Возможно, мы можем устроить в в в в.\n",
            "ATT: Возможно, у нас есть небольшая медаль в посредничества.\n",
            "\n",
            "=== Пример 4 ===\n",
            "SRC: How long is it going to take you to get him what he needs?\n",
            "REF: Сколько времени вы будете делать то, что ему нужно?\n",
            "S2S: Сколько времени тебе нужно это, чтобы он, что?\n",
            "ATT: Сколько времени тебе нужно, чтобы он его, что?\n",
            "\n",
            "=== Пример 5 ===\n",
            "SRC: On 1 April President of the Nagorno Karabagh Republic Bako Sahakyan met head of the General Staff of the Republic of Armenia's Armed forces colonel-general Yuri Khachaturov.\n",
            "REF: 1 апреля Президент НКР Бако Саакян принял начальника Генштаба Вооруженных сил Республики Армения генерал-полковника Юрия Хачатурова.\n",
            "S2S: 1 апреля Президент Республики Арцах Республики Набарбаева встретился с армянской армии армянской Республики Арцаха Республики Сербей Балко-Шаа.\n",
            "ATT: 1 апреля Президент Нагор Карабахской Республики Бако Саакян встретился с руководителем военнослужащих сил обороны Армении, армянского союза, генерала-а-ауара.\n",
            "\n",
            "=== Пример 6 ===\n",
            "SRC: Mr Priesner also noted that the E-justice management system has not only improved case management, but has also led to a significant streamlining in procedures.\n",
            "REF: Г-н Приснер также упомянул, что система электронного правосудия не только позволила улучшить процесс ведения дел, но также способствует значительному упорядочению процедур.\n",
            "S2S: Г-н Энер также отметил, что также система управления управления не только в новом процессе, но также, что, что процесс управления процессами не только в улучшенной степени.\n",
            "ATT: Г-н Мернер также отметил, что система управления системами-за не не только улучшение управления, но и привело к значительному использованию в процессе процедур.\n",
            "\n",
            "=== Пример 7 ===\n",
            "SRC: You don't like chicken noodle soup?\n",
            "REF: - Неплохо, да.\n",
            "S2S: Ты не любишь куплю куп?\n",
            "ATT: Ты не любишь курица куп?\n",
            "\n",
            "=== Пример 8 ===\n",
            "SRC: Posted: 14 May 2005, 20:31\n",
            "REF: Posted: 15 Dec 2006, 00:07\n",
            "S2S: Posted: 14 May 2006, 20:01\n",
            "ATT: Posted: 14 May 2005, 14:31\n",
            "\n",
            "=== Пример 9 ===\n",
            "SRC: Now, for a minute, I thought maybe he was being tailed.\n",
            "REF: И на минутку я подумал, что за ним могут следить.\n",
            "S2S: А теперь, я думаю, я думал, что он может быть.\n",
            "ATT: А теперь, я думала, что он может быть.\n",
            "\n",
            "=== Пример 10 ===\n",
            "SRC: « : 26 Октябрь 2017, 06:50:24 »\n",
            "REF: «: 11 Октябрь 2011, 17:15:34»\n",
            "S2S: « : 26 Сентябрь 2011, 16:48:50 »\n",
            "ATT: « : Июль 2011, 08:11:24 »\n",
            "\n",
            "=== Пример 11 ===\n",
            "SRC: The Societies Act Chapter 66 (1972) requires any club, company, partnership or association of 10 or more persons except as provided under Section 2 of the Act, to be registered with the Registrar of Societies.\n",
            "REF: Закон об объединениях, глава 66, (1972 год) требует, чтобы любой клуб, компания, товарищество или ассоциация, насчитывающие 10 или более человек, за исключением тех случаев, которые предусмотрены в разделе 2 этого закона, были внесены в регистр объединений.\n",
            "S2S: В Законе об Законе об обеспечении безопасности, в, в, или, или, или, или, или,,, или,,, или,,, или,,, или,,, или в соответствии с статьей 10 Закона о статусе или в.\n",
            "ATT: Закон о Законом о 66х (1972) требует любой-либо,,,, партнерство или объединения или или или или, кроме исключением случаев, предусмотренных в соответствии с Законом, который зарегистрирован в реестр регистрации общественных организаций.\n",
            "\n",
            "=== Пример 12 ===\n",
            "SRC: Half of the Kazakhstan top managers interviewed said that global economic conditions will not change in the next 12 months.\n",
            "REF: По мнению половины опрошенных казахстанских руководителей высшего звена, состояние мировой экономики в течение ближайших 12 месяцев не изменится.\n",
            "S2S: Половина мировых валют сказал, что условия, которые не будут в состоянии в условиях, месяцев назад.\n",
            "ATT: Половина Казахстана, в котором в интервью, что, что экономические экономические условия не изменится в следующем месяце.\n",
            "\n",
            "=== Пример 13 ===\n",
            "SRC: A collection from the Adams administration.\n",
            "REF: Коллекция администрации Адамса.\n",
            "S2S: Сбор из Амада.\n",
            "ATT: Обор из Адам Адам.\n",
            "\n",
            "=== Пример 14 ===\n",
            "SRC: Cost effective flow measurement\n",
            "REF: Экономичное средство измерения расхода\n",
            "S2S: Эффектив эффективное измерение измерения\n",
            "ATT: Утоканое измерение\n",
            "\n",
            "=== Пример 15 ===\n",
            "SRC: Tuyo Movil 571 *****\n",
            "REF: Tuyo Movil 571 *****\n",
            "S2S: Tuuo111\n",
            "ATT: Tuyo Movil 571 *****\n",
            "\n",
            "=== Пример 16 ===\n",
            "SRC: This can be very useful if you know you will not promote and want to sign a new driver as you can effectively write off your driver offer & signing fees as the money is reset and all you will be left with is the driver salary for the following season. More about this in the next section.\n",
            "REF: Если вы точно уверены, что не продвинетесь выше в этом сезоне, то может оказаться очень полезно ближе к концу сезона нанять себе очень хорошего пилота, так как можно не обращать внимание на затраты за предложения контрактов и премии за их подписание – деньги всё равно вернутся в исходное состояние и вы останетесь с этим же пилотом в следующем сезоне. Подробнее об этом в следующем разделе.\n",
            "S2S: Это может быть полезно, если вы можете узнать, что вы можете,, вы можете, чтобы вы не сможете использовать в в и и, и вы можете добавить в в в в, и вы можете добавить в в в в в в, в в в в, в в будет добавить в в в.\n",
            "ATT: Это может быть очень полезным, если вы знаете, что не будет поощрять и хотите подписать новый водитель, как вы можете можете писать вашемуюду и и подписать в качестве деньги, и остаются, и вы оставляетесь в этом, что для сайт для сезона.\n",
            "\n",
            "=== Пример 17 ===\n",
            "SRC: Ah, so hungry.\n",
            "REF: Есть охота.\n",
            "S2S: Ах, голод.\n",
            "ATT: Ах, голод.\n",
            "\n",
            "=== Пример 18 ===\n",
            "SRC: You don't even want to set one foot in the hospital?\n",
            "REF: Ты в больнице носа не показываешь?\n",
            "S2S: Ты даже не хочешь в больницу в больницу?\n",
            "ATT: Ты даже не хочешь вть в больницу?\n",
            "\n",
            "=== Пример 19 ===\n",
            "SRC: That is who's doing this to you.\n",
            "REF: Этот тот, кто сделал это с тобой.\n",
            "S2S: Это так, что ты.\n",
            "ATT: Это кто это делает тебя.\n",
            "\n",
            "=== Пример 20 ===\n",
            "SRC: http://www.culturalnet.ru/f/viewtopic.php?id=1305\n",
            "REF: http://www.culturalnet.ru/f/viewtopic.php?id=1611\n",
            "S2S: http://www.cfc.ru/ru/viewtopic.php?f=1&t=5\n",
            "ATT: http://www.culturalnet.ru/f/viewtopic.php?id=1305\n",
            "\n",
            "=== Пример 21 ===\n",
            "SRC: - Do you understand that... that...\n",
            "REF: Ты понимаешь, что...\n",
            "S2S: - Ты понимаешь, что...\n",
            "ATT: - Ты понимаешь, что...\n",
            "\n",
            "=== Пример 22 ===\n",
            "SRC: Maybe the ma ⁇ tre'd will tell me how it went!\n",
            "REF: Но я ничего не увижу. - Дорогая... Может, метрдотель расскажет мне, как всё прошло.\n",
            "S2S: Может, мясник, как мне сказать, как она!\n",
            "ATT: Может, мадам не расскажет мне, как она!\n",
            "\n",
            "=== Пример 23 ===\n",
            "SRC: - You're instructed to land immediately.\n",
            "REF: Призрак, вам приказано посадить самолет. Выходите на посадку немедленно.\n",
            "S2S: - Ты поручил немедленно немедленно.\n",
            "ATT: - Вы немедленно отправились немедленно.\n",
            "\n",
            "=== Пример 24 ===\n",
            "SRC: Documents are being accepted up to December 28, 2006.\n",
            "REF: Документы принимаются до 28 декабря 2006 г. включительно.\n",
            "S2S: Документы,ются в декабре 2006 года.\n",
            "ATT: Документы принимаются в декабре 2006 года.\n",
            "\n",
            "=== Пример 25 ===\n",
            "SRC: Year after year, I can't let go\n",
            "REF: √оды проход€т, ј € не могу забыть\n",
            "S2S: Год год, я не могу уйти.\n",
            "ATT: Год за год, я не могу уйти\n",
            "\n",
            "=== Пример 26 ===\n",
            "SRC: Sustainable Energy Division\n",
            "REF: Sustainable Energy Division\n",
            "S2S: Устойчивое управление\n",
            "ATT: Устойчивое энергетическое\n",
            "\n",
            "=== Пример 27 ===\n",
            "SRC: They're off!\n",
            "REF: - Они отключились. - Алло?\n",
            "S2S: Они ушли!\n",
            "ATT: Они ушли!\n",
            "\n",
            "=== Пример 28 ===\n",
            "SRC: 04. The Voice Of Tibet (Our Shame And Hypocrisy)\n",
            "REF: U (19) V (19)\n",
            "S2S: 04. The Hibice Tour Tour Tour ( (H.\n",
            "ATT: 04. The Voice Of Tibet (Our Shame And Hypocrisy)\n",
            "\n",
            "=== Пример 29 ===\n",
            "SRC: How can a person have no heat?\n",
            "REF: Как может тело не греть?\n",
            "S2S: Как же может быть не теря?\n",
            "ATT: Как может может быть жалеть?\n",
            "\n",
            "=== Пример 30 ===\n",
            "SRC: There are 56 boarding schools, six homes for over-fives and two for under-fives for children with physical or mental disabilities, children lacking parental protection and orphaned and abandoned children.\n",
            "REF: Для детей с дефектами умственного и физического развития, лишенных родительской опеки, сирот и брошенных детей, действует 56 интернатов, 6 детских домов, 2 дома ребенка.\n",
            "S2S: В 6-х детей, детей в возрасте до шести лет, и детей, детей, детей, детей, а также физические и психические и,,ные средства для детей, не имеющих детей, не имеющих детей, а также для детей.\n",
            "ATT: В школах, в которых проживают в домашних хозяйстве, шесть детей для детей и детей, физических или психического психиа, детей, детей, родительской защиты и детей, а также детей.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def decode_ids(ids):\n",
        "    clean = []\n",
        "    for i in ids:\n",
        "        if i in (PAD_ID, BOS_ID):\n",
        "            continue\n",
        "        if i == EOS_ID:\n",
        "            break\n",
        "        clean.append(i)\n",
        "    return sp.decode(clean)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_translate_s2s(model, src_batch, src_len):\n",
        "    model.eval()\n",
        "    src_batch = src_batch.to(DEVICE)\n",
        "    src_len = src_len.to(DEVICE)\n",
        "\n",
        "    enc_outs, hidden = model.encoder(src_batch, src_len)\n",
        "    B = src_batch.size(0)\n",
        "    input_tok = torch.full((B,), BOS_ID, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "    finished = torch.zeros(B, dtype=torch.bool, device=DEVICE)\n",
        "    outputs = [[] for _ in range(B)]\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "        logits, hidden = model.decoder(input_tok, hidden)\n",
        "        next_tok = logits.argmax(dim=-1)\n",
        "        for i in range(B):\n",
        "            if not finished[i]:\n",
        "                outputs[i].append(next_tok[i].item())\n",
        "                if next_tok[i].item() == EOS_ID:\n",
        "                    finished[i] = True\n",
        "        if finished.all():\n",
        "            break\n",
        "        input_tok = next_tok\n",
        "\n",
        "    return [decode_ids(seq) for seq in outputs]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_translate_attn(model, src_batch, src_len):\n",
        "    model.eval()\n",
        "    src_batch = src_batch.to(DEVICE)\n",
        "    src_len = src_len.to(DEVICE)\n",
        "    src_mask = make_src_mask(src_batch)\n",
        "\n",
        "    enc_outs, hidden = model.encoder(src_batch, src_len)\n",
        "    B = src_batch.size(0)\n",
        "    input_tok = torch.full((B,), BOS_ID, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "    finished = torch.zeros(B, dtype=torch.bool, device=DEVICE)\n",
        "    outputs = [[] for _ in range(B)]\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "        logits, hidden = model.decoder(input_tok, hidden, enc_outs, src_mask)\n",
        "        next_tok = logits.argmax(dim=-1)\n",
        "        for i in range(B):\n",
        "            if not finished[i]:\n",
        "                outputs[i].append(next_tok[i].item())\n",
        "                if next_tok[i].item() == EOS_ID:\n",
        "                    finished[i] = True\n",
        "        if finished.all():\n",
        "            break\n",
        "        input_tok = next_tok\n",
        "\n",
        "    return [decode_ids(seq) for seq in outputs]\n",
        "\n",
        "\n",
        "# Загрузка лучших весов после обучения (раскомментировать при наличии файлов):\n",
        "model_s2s.load_state_dict(torch.load(MODEL_S2S_PATH, map_location=DEVICE))\n",
        "model_attn.load_state_dict(torch.load(MODEL_ATT_PATH, map_location=DEVICE))\n",
        "\n",
        "\n",
        "def sample_test_batch(n=30):\n",
        "    subset = [ds_test[i] for i in range(min(n, len(ds_test)))]\n",
        "    src_list = []\n",
        "    tgt_text = []\n",
        "    for ex in subset:\n",
        "        tr = ex[\"translation\"]\n",
        "        src_list.append(encode_text(tr[LANG_SRC]))  # or tr[SRC_LANG]\n",
        "        tgt_text.append(tr[LANG_TGT])  # or tr[TGT_LANG]\n",
        "    src_pad = pad_sequence_sp(src_list)\n",
        "    src_len = (src_pad != PAD_ID).sum(dim=1)\n",
        "    return src_pad, src_len, tgt_text\n",
        "\n",
        "\n",
        "src_pad, src_len, tgt_gold = sample_test_batch(30)\n",
        "pred_s2s = greedy_translate_s2s(model_s2s, src_pad, src_len)\n",
        "pred_att = greedy_translate_attn(model_attn, src_pad, src_len)\n",
        "\n",
        "for i in range(len(tgt_gold)):\n",
        "    print(f\"=== Пример {i+1} ===\")\n",
        "    print(\"SRC:\", decode_ids(src_pad[i].tolist()))\n",
        "    print(\"REF:\", tgt_gold[i])\n",
        "    print(\"S2S:\", pred_s2s[i])\n",
        "    print(\"ATT:\", pred_att[i])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ccc9b8",
      "metadata": {},
      "source": [
        "## В целом модели работают, по крайней мере для коротких простых предложений."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
